{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.1-py3-none-win_amd64.whl (97.8 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\gnana\\anaconda3\\lib\\site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\gnana\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dicom\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import gc\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json\n",
    "import itertools\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing libraries'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/gnana/Downloads/x_test_96.npy/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to load train images: 0.53337 seconds.\n",
      "train_images shape:  (33126, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "train_images = np.load('C:/Users/gnana/Downloads/x_test_96.npy/x_train_96.npy')\n",
    "end=time.time()\n",
    "print(f\"\\nTime to load train images: {round(end-start,5)} seconds.\")\n",
    "print('train_images shape: ',train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_labels shape:  (33126, 1)\n"
     ]
    }
   ],
   "source": [
    "#target data\n",
    "train_labels =np.array(train.drop(['image_name', 'patient_id', 'sex', 'age_approx',\n",
    "       'anatom_site_general_challenge', 'diagnosis','benign_malignant'],axis=1))\n",
    "print('Train_labels shape: ',train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val=train_test_split(train_images,train_labels,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (23188, 96, 96, 3)\n",
      "x_val shape:  (9938, 96, 96, 3)\n",
      "y_val shape:  (9938, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ',x_train.shape)\n",
    "print('x_val shape: ',x_val.shape)\n",
    "print('y_val shape: ',y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('C:/Users/gnana/vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('C:/Users/gnana/vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09649145603179932\n",
      "Test accuracy: 0.9804789423942566\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.axis\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.moving_mean\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.moving_variance\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model_ = keras.models.load_model('C:/Users/gnana/xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.load_weights('C:/Users/gnana/xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4816811084747314\n",
      "Test accuracy: 0.9804789423942566\n"
     ]
    }
   ],
   "source": [
    "scores = model_.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r'C:/Users/gnana/X_test.csv')\n",
    "y_test = pd.read_csv(r'C:/Users/gnana/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6797265114849812\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "filename = 'C:/Users/gnana/finalized_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result1 = loaded_model.score(X_test, y_test)\n",
    "print(result1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  \n",
       "0   unknown           benign       0  \n",
       "1   unknown           benign       0  \n",
       "2     nevus           benign       0  \n",
       "3   unknown           benign       0  \n",
       "4   unknown           benign       0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/gnana/Downloads/train.csv/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33026</th>\n",
       "      <td>ISIC_9971896</td>\n",
       "      <td>IP_7261254</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33027</th>\n",
       "      <td>ISIC_9972518</td>\n",
       "      <td>IP_0892152</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33028</th>\n",
       "      <td>ISIC_9972557</td>\n",
       "      <td>IP_7040211</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33029</th>\n",
       "      <td>ISIC_9973015</td>\n",
       "      <td>IP_0583343</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33030</th>\n",
       "      <td>ISIC_9973089</td>\n",
       "      <td>IP_1969685</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  patient_id     sex  age_approx  \\\n",
       "33026  ISIC_9971896  IP_7261254  female        20.0   \n",
       "33027  ISIC_9972518  IP_0892152    male        50.0   \n",
       "33028  ISIC_9972557  IP_7040211    male        50.0   \n",
       "33029  ISIC_9973015  IP_0583343    male        65.0   \n",
       "33030  ISIC_9973089  IP_1969685    male        50.0   \n",
       "\n",
       "      anatom_site_general_challenge diagnosis benign_malignant  target  \n",
       "33026                         torso   unknown           benign       0  \n",
       "33027               upper extremity   unknown           benign       0  \n",
       "33028                     head/neck   unknown           benign       0  \n",
       "33029                         torso   unknown           benign       0  \n",
       "33030                         torso   unknown           benign       0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.tail(100)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Getting the images data and flattening them'''\n",
    "\n",
    "test_images = []\n",
    "for x in test['image_name']:\n",
    "    image = 'C:/Users/gnana/Downloads/train/' + x +'.dcm'\n",
    "    ds = dicom.dcmread(image)\n",
    "    pixels = ds.pixel_array\n",
    "    \n",
    "    test_images.append(pixels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pad_sequences is used to ensure that all sequences in a list have the same length'''\n",
    "\n",
    "test_images = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "  test_images,\n",
    "  maxlen = 720,\n",
    "  dtype = \"int32\",\n",
    "  padding = \"pre\",\n",
    "  truncating = \"pre\",\n",
    "  value = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Predicting the test data using Logistic Regression'''\n",
    "\n",
    "X_test = test_images\n",
    "y_test = np.array(test['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "filename = r'C:\\Users\\gnana\\Logistic_model.sav'\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Prepare training data'''\n",
    "\n",
    "filenames = os.listdir(\"/Users/prathyusha/Desktop/pranathi/ADS/project/train/\")\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    \n",
    "    if 'benign' in filename:\n",
    "        categories.append(0)\n",
    "    else:\n",
    "        categories.append(1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Imagenerator will convert it one-hot encoding and we will convert 1 to malignant and 0 to benign'''\n",
    "\n",
    "df[\"category\"] = df[\"category\"].replace({0: 'benign', 1: 'malignant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30662, 2)\n",
      "(7666, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test_df = train_test_split(df,stratify=df[\"category\"], test_size=0.20, random_state=42)\n",
    "train = train.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True) \n",
    "\n",
    "print(train.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining constants\n",
    "\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd453237220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"/Users/prathyusha/Desktop/pranathi/ADS/project/model1.h7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benign5332.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benign2937.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>augmented_image_1190.jpg</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>augmented_image_1944.jpg</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benign14363.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename   category\n",
       "0            benign5332.jpg     benign\n",
       "1            benign2937.jpg     benign\n",
       "2  augmented_image_1190.jpg  malignant\n",
       "3  augmented_image_1944.jpg  malignant\n",
       "4           benign14363.jpg     benign"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7666 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "'''Rescaling and reshaping the test images'''\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    \"/Users/prathyusha/Desktop/pranathi/ADS/project/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    class_mode='binary',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=15,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathyusha/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n",
      "/Users/prathyusha/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30772659182548523\n",
      "Test accuracy: 0.835898756980896\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(['VGG16', 'DenseNet', 'XGBoost','Logistic Regression', 'CNN'], accuracy,\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
